{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis of Bind-n-seq using Bicc1 protein\n",
    "\n",
    "\n",
    "The first version was written in Julia 1.1.1.\n",
    "The current version is written in Julia 1.6.0. (2021-05-05)\n",
    "\n",
    "Written by Kaoru R Komatsu and Emi Miyashita  \n",
    "Conducted by Kaoru R Komatsu\n",
    "\n",
    "Quality filters remove the following reads.\n",
    "+ Duplicated reads\n",
    "+ Average Qscore is less than 30.\n",
    "+ Length is not 20nt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using BioJulia for counting K-mer\n",
    "using Bio.Seq\n",
    "#comp = composition(each(DNAKmer{4}, dna\"ACGTTTCGAACGT\"))#test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames,Statistics,StatsBase, Gadfly, CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topkmer (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate_mers(alphabet, k)\n",
    "    kmer_set = [\"\"]\n",
    "    for i in 1:k\n",
    "        new_kmers =[o * alphabet[j] for o in kmer_set for j in 1:length(alphabet)]\n",
    "        kmer_set = new_kmers\n",
    "    end\n",
    "    sort(kmer_set)\n",
    "    return kmer_set\n",
    "end\n",
    "                \n",
    "    \n",
    "function generate_mers_rank_map(alphabet, k)\n",
    "\n",
    "    kmer_set = generate_mers(alphabet, k)\n",
    "    rank_dict = Dict()\n",
    "    for (i, o) in enumerate(kmer_set)\n",
    "        rank_dict[o] = 0\n",
    "    end\n",
    "    return rank_dict\n",
    "end\n",
    "                \n",
    "function str2kmers(s, k)\n",
    "    out = []\n",
    "    for i in 1:length(s)- k +1\n",
    "        push!(out,s[i:i+k-1])\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "                \n",
    "                \n",
    "function Topkmer(kmer_set,rank_map,datasets)\n",
    "    out =  ist()\n",
    "    for kmer in kmer_set\n",
    "        ten = list()\n",
    "        rank = rank_map[kmer]  \n",
    "        for d in sorted(datasets)\n",
    "            push!(ten, counts_by_name[d][rank])#Dict->list->num\n",
    "        end\n",
    "        push!(out,sum(ten))\n",
    "    end\n",
    "    top_enriched_kmer_list = [[i,v/sum(out)] for (i,v) in zip(kmer_set,out) if v == max(out)]\n",
    "    return(top_enriched_kmer_list[0][0])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df2kmer_table (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function open_fastq_and_profile_kmer(fastq_file, knum, qscore)\n",
    "    dna_alphabet = [\"A\", \"C\", \"G\", \"T\"]\n",
    "    kmer_set = generate_mers(dna_alphabet, knum)\n",
    "    rank_map = generate_mers_rank_map(dna_alphabet, knum)\n",
    "\n",
    "    reader = open(FASTQ.Reader, fastq_file)\n",
    "    linecount = 0\n",
    "    linecount_highqc = 0\n",
    "    sequencedict = Dict{String,Int64}()\n",
    "    duplicated_dict = Dict{String,Int64}()\n",
    "    \n",
    "    println(\"#######Loading#######\")\n",
    "    duplicate = false\n",
    "    for record in reader \n",
    "        tseq = (convert(String,FASTQ.sequence(record)))\n",
    "        qc = FASTQ.quality(record)\n",
    "        linecount +=1\n",
    "    \n",
    "        \n",
    "        if (length(tseq) == 20) && (mean(qc) >= qscore)\n",
    "            \n",
    "            # To remove PCR duplicates\n",
    "            if haskey(sequencedict,tseq)\n",
    "                duplicate = true\n",
    "                if haskey(duplicated_dict,tseq)\n",
    "                    duplicated_dict[tseq]  += 1\n",
    "                else\n",
    "                     duplicated_dict[tseq]  = 1\n",
    "                end\n",
    "            else\n",
    "                duplicate = false\n",
    "            end\n",
    "                \n",
    "            linecount_highqc +=1\n",
    "            comp = composition(each(DNAKmer{knum},DNASequence(string(FASTQ.sequence(record)))))\n",
    "            \n",
    "            for (kmer, count) in convert(Dict,comp)\n",
    "                \n",
    "                if (!occursin(\"N\", string(kmer))) \n",
    "                    if (duplicate ==false)\n",
    "                        prevcount = rank_map[convert(String,kmer)]\n",
    "                        rank_map[convert(String,kmer)] = prevcount + count\n",
    "                        sequencedict[tseq] = 1\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "    end\n",
    "    println(\"total \",linecount,\" sequences\")\n",
    "    println(\"High QC \",linecount_highqc,\" sequences\")\n",
    "    println(\"(Removed) Suspected PCR-replicates: \", length(duplicated_dict))\n",
    "    println(\"Removed \", length(duplicated_dict),\"reads\")\n",
    "    return rank_map\n",
    "    close(reader)\n",
    "end\n",
    "\n",
    "\n",
    "function df2kmer_table(file1,file2,outputname)\n",
    "\n",
    "    dfL2 = sort(DataFrame(Dict(reverse(collect(file1)))))\n",
    "    dfL4 = sort(DataFrame(Dict(reverse(collect(file2)))))\n",
    "    Bicc1 = collect(dfL2[1,:])/sum(collect(dfL2[1,:]))\n",
    "    Control = collect(dfL4[1,:])/sum(collect(dfL4[1,:]))\n",
    "    Enrich_Div = Bicc1./Control \n",
    "    zEnrich_Div = zscore(Enrich_Div)\n",
    "    Zscore = zscore(collect(map((x,y)-> (x ./sum(dfL2[1,:]))/(y ./sum(dfL4[1,:])), values(dfL2[1,:]), values(dfL4[1,:]))))\n",
    "\n",
    "    dfL24 = DataFrame(\n",
    "        Kmer=names(dfL2),\n",
    "        Frequency_Bicc1 = collect(dfL2[1,:]),\n",
    "        Frequency_Control = collect(dfL4[1,:]),\n",
    "        NormalizedFrequency_Bicc1 = Bicc1 ,\n",
    "        NormalizedFrequency_Control = Control,\n",
    "        RelativeFrequency = Enrich_Div,\n",
    "        RelativeFrequency_Zscore = zEnrich_Div)\n",
    "            \n",
    "    sort!(dfL24, :RelativeFrequency, rev=true)\n",
    "    dfL24 |> CSV.write(outputname ,delim=',',writeheader=true)        \n",
    "    return dfL24\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Loading#######\n",
      "total 832224 sequences\n",
      "High QC 715319 sequences\n",
      "(Removed) Suspected PCR-replicates: 183\n",
      "Removed 183reads\n",
      "#######Loading#######\n",
      "total 937217 sequences\n",
      "High QC 780761 sequences\n",
      "(Removed) Suspected PCR-replicates: 8757\n",
      "Removed 8757reads\n",
      "#######Loading#######\n",
      "total 832224 sequences\n",
      "High QC 715319 sequences\n",
      "(Removed) Suspected PCR-replicates: 183\n",
      "Removed 183reads\n",
      "#######Loading#######\n",
      "total 937217 sequences\n",
      "High QC 780761 sequences\n",
      "(Removed) Suspected PCR-replicates: 8757\n",
      "Removed 8757reads\n",
      "#######Loading#######\n",
      "total 832224 sequences\n",
      "High QC 715319 sequences\n",
      "(Removed) Suspected PCR-replicates: 183\n",
      "Removed 183reads\n",
      "#######Loading#######\n",
      "total 937217 sequences\n",
      "High QC 780761 sequences\n",
      "(Removed) Suspected PCR-replicates: 8757\n",
      "Removed 8757reads\n"
     ]
    }
   ],
   "source": [
    "cd(\"/Users/krk/Desktop/Bicc1-dand5/Rawdata/\")\n",
    "for i in [4,5,6]\n",
    "    kmer_Bicc = open_fastq_and_profile_kmer(\"./190523_bindN/Data/Intensities/BaseCalls/L3_RBNS_BICCd4.fastq\",i, 30)\n",
    "    kmer_Mock = open_fastq_and_profile_kmer(\"./190523_bindN/Data/Intensities/BaseCalls/L4_Mock.fastq\",i, 30)\n",
    "    dfout = df2kmer_table(kmer_Bicc, kmer_Mock,\"RelativeFrequency_$(i)mer.csv\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
